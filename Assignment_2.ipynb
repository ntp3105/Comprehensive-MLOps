{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qMLBBS5ZGWUU",
        "yKbGL0zOGb2l",
        "ZwBMt6VJGeW-",
        "c1p1JzJWGhvH"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ntp3105/IISc-CCE-ML-AI-MLOps/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical AI and MLOps : Assignment 2\n",
        "\n"
      ],
      "metadata": {
        "id": "WA4bucbhF6wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download the datasets.\n",
        "\n",
        "The datasets are downloaded and stored in pandas dataframes `df1` and `df2`. You are free to change the names as you like. You can split the datasets using `train_test_split` function from the `scikit-learn` library.\n",
        "\n",
        "**1st dataset:** (df1) For problems 1, 2, 3 and 4\n",
        "\n",
        "**2nd dataset:** (df2) For problem 5"
      ],
      "metadata": {
        "id": "Musg62sg30Rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT EDIT\n",
        "\n",
        "!pip install gdown\n",
        "!gdown 18NuvJotUFiTAHW0YgaoLVu2blW_V6YX0\n",
        "!unzip -o /content/assignment2.zip -d data\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df1 = pd.read_csv('/content/data/assignment2-1.csv')\n",
        "df2 = pd.read_csv('/content/data/assignment2-2.csv')"
      ],
      "metadata": {
        "id": "JgXSETyW3mQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c122ee4-2b9d-4d47-e52a-0b38d97e1ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: typing-extensions>=4.7.1 in /usr/local/lib/python3.10/dist-packages (from filelock->gdown) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.7.22)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18NuvJotUFiTAHW0YgaoLVu2blW_V6YX0\n",
            "To: /content/assignment2.zip\n",
            "100% 120M/120M [00:03<00:00, 33.0MB/s]\n",
            "Archive:  /content/assignment2.zip\n",
            "  inflating: data/assignment2-1.csv  \n",
            "  inflating: data/assignment2-2.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem and Dataset Description"
      ],
      "metadata": {
        "id": "gApLH-475U9w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have been provided with a dataset containing various attributes about the behavior of an online shopper and whether they made a purchase or not. Your task is to build a decision tree model to predict whether a visitor to the webpage actually made a purchase or not based on the provided attributes.\n",
        "\n",
        "Dataset columns:\n",
        "\n",
        "*   Electronic_Devices : the number of pages of electronic devices visited by the shopper in a session\n",
        "*   Electronic_Devices_Duration : the total time spent in electronic devices category by the shopper\n",
        "*   Groceries : the number of pages of groceries visited by the shopper\n",
        "*   Groceries_Duration : the total time spent in groceries category by the shopper\n",
        "*   Sports_Equipments : the number of pages of sports equipments visited by the shopper\n",
        "*   Sports_Equipments_Duration : the total time spent in sports equipments category by the shopper\n",
        "*   Bounce_Rates : this feature for a web page refers to the percentage of visitors who enter the site from that page and then leave (\"bounce\") without triggering any other requests\n",
        "*   Special_Day : this feature indicates the closeness of the site visiting time to a specific special day (e.g. Motherâ€™s Day, Independence Day)\n",
        "*   Month : the specific month of the year\n",
        "*   Browser : the browser used by the shopper\n",
        "*   Region : the region where the searches were made\n",
        "*   Type_of_visitor : this feature indicates whether the shopper is a returning or new visitor to the page\n",
        "*   Weekend : Boolean value indicating whether the date of the visit is weekend\n",
        "*   Purchase_made : Boolean value indicating whether the purchase was made or not"
      ],
      "metadata": {
        "id": "9oTgt989X6-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1: Decision Tree (2 Marks)"
      ],
      "metadata": {
        "id": "qMLBBS5ZGWUU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1.   Using the provided dataset, build a decision tree model that can predict whether a visitor will make a purchase during their online session. Additionally, evaluate the performance of your decision tree model using appropriate metrics such as accuracy, precision, recall, and F1-score.\n",
        "2.   Which attribute(s) did your decision tree identify as the most important for predicting whether a visitor will make a purchase or not?\n",
        "3.   What is the maximum depth of your decision tree and how did you estimate it?\n",
        "4.   What is the accuracy of your decision tree model in predicting purchase behavior, and did you employ any techniques to handle categorical features or missing values in the dataset?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QUoMW8UzcLcO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Write your code and answers here\n",
        "\n",
        "\n",
        "# grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TrKwRWV8GbO2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2: Random Forest (1 mark)\n",
        "\n",
        "\n",
        "1.   Implement a Random Forest classifier with a specified number of trees (e.g., 100 trees).Train the Random Forest classifier on the training data.\n",
        "2.   Evaluate the model's performance using appropriate metrics (e.g., accuracy, precision, recall, F1-score) on the testing data."
      ],
      "metadata": {
        "id": "yKbGL0zOGb2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Write your code and answers here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gqbgoOnQGeCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 3: Bagging with Pruning (1 mark)\n",
        "\n",
        "\n",
        "\n",
        "1.   Define the mathematical criterion for pruning a decision tree within the Bagging with Pruning ensemble. Explain how this criterion helps prevent overfitting.\n",
        "2.   When applying bagging with pruning to decision trees in the dataset, how do you decide when to prune a branch or subtree in each individual tree, and how does this ensemble approach help reduce overfitting compared to a single decision tree?\n",
        "\n"
      ],
      "metadata": {
        "id": "ZwBMt6VJGeW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Write your code and answers here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j73yX9Xj37rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 4: Boosting and XG Boost (1 mark)\n",
        "\n",
        "\n",
        "\n",
        "1.   Implement an AdaBoost classifier witha specified number of weak learners. You can use Skikit-learn's AdaBoost classifier. Train the AdaBoost classifier on the training data. Evaluate the model's performance using appropriate classification metrics (e.g., accuracy, precision, recall, F1-score) on the testing data.\n",
        "2.   Visualize the decision boundaries of the AdaBoost model by selecting two features from the dataset and creating a 2D plot that shows how the model separates the classes.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c1p1JzJWGhvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Write your code and answers here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "+\n"
      ],
      "metadata": {
        "id": "iqQwnDHclu61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 5: Unsupervised Learning (5 marks)\n",
        "\n",
        "You are given a dataset, which contains sensor data. Your task is to apply dimensionality reduction and clustering techniques on this dataset using Principal Component Analysis (PCA), K-means, and Linear Discriminant Analysis (LDA).\n",
        "\n",
        "## Part 1: PCA (1 mark)\n",
        "**a.** Apply PCA to reduce the dimensionality of the dataset.\n",
        "\n",
        "**b.** Calculate the percentage of variance explained by each principal component.\n",
        "\n",
        "**c.** Plot a scree plot to visualize the percentage of variance explained by each principal component.\n",
        "\n",
        "**d.** Discuss the importance of dimensionality reduction using PCA in the context of the HAR dataset.\n",
        "\n",
        "## Part 2: K-means (2 marks)\n",
        "**a.** Apply K-means clustering on the reduced-dimensional dataset obtained from PCA.\n",
        "\n",
        "**b.** Use the elbow method to determine the optimal number of clusters.\n",
        "\n",
        "**c.** Visualize and interpret the results of the K-means clustering.\n",
        "\n",
        "**d.** Evaluate the quality of the clustering solution using appropriate metrics such as silhouette score or within-cluster sum of squares.\n",
        "\n",
        "## Part 3: LDA (2 marks)\n",
        "**a.** Apply LDA to project the dataset onto a lower-dimensional space that maximizes class separability.\n",
        "\n",
        "**b.** Perform K-means clustering on the reduced-dimensional dataset obtained from LDA.\n",
        "\n",
        "**c.** Compare the clustering results obtained from LDA with the results obtained from PCA and discuss the differences.\n",
        "\n",
        "**d.** Evaluate the effectiveness of LDA in improving the clustering performance compared to PCA.\n",
        "\n",
        "**Note:** You can use any libraries of your choice to implement PCA, K-means, and LDA on the UCI HAR Dataset. Provide code snippets, visualizations, and detailed explanations to support your answers. Consider discussing the interpretability of the reduced-dimensional space, the impact of different clustering parameters, and any challenges encountered during the analysis."
      ],
      "metadata": {
        "id": "BfomFmpKDIHa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Hs8vnJ1DQbE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}